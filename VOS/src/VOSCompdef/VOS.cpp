// --------------------------------------------------------
// Code generated by Papyrus C++
// --------------------------------------------------------

#define VOSCompdef_VOS_BODY

/************************************************************
 VOS class body
 ************************************************************/

// include associated header file
#include "../../src/VOSCompdef/VOS.h"

// Derived includes directives
//#include "rclcpp/rclcpp.hpp"


// Include from Include declaration (body)
// declare options
rclcpp::NodeOptions vos_options;


// Output segmentation mask that is computed in segmentImage
static cv::Mat seg_mask;

// Used during evaluation of the model
static torch::Tensor runningFGmean;
static torch::Tensor runningBGmean;

static int count = 0;


static auto img_msg = sensor_msgs::msg::Image();

void segmentImage( Mat& img , torch::jit::script::Module module );


const std::string annotated_path = "./VOS/annotated_frame.jpg";
const std::string model_path = "./VOS/tracedModel_cov_CPU.pt";


int main(int argc, char **argv) {
	rclcpp::init(argc, argv);

	auto vos = std::make_shared<VOSCompdef::VOS>(vos_options);
	cv_bridge::CvImage segmentation;


	torch::jit::script::Module module;
	module = torch::jit::load(model_path);


	RCLCPP_INFO(vos->get_logger(), "VOS has been initialized");

	rclcpp::executors::MultiThreadedExecutor executor;

	executor.add_node(vos->get_node_base_interface());

	while (rclcpp::ok())
	{

		cv::Mat cv_mat(img_msg.height, img_msg.width, CV_8UC3,img_msg.data.data());
		cv::Mat c_mat = cv_mat;

		if( !c_mat.empty() )
		{
			char c = (char)waitKey(10);
			RCLCPP_INFO(vos->get_logger(), "Processing Image...");
			segmentImage( c_mat , module );
			RCLCPP_INFO(vos->get_logger(), "Finished!");

			// Press q to exit from window
			if( c == 27 || c == 'q' || c == 'Q' )
				break;

			segmentation.header = img_msg.header;
			segmentation.encoding = sensor_msgs::image_encodings::TYPE_8UC1;
			segmentation.image = seg_mask;

			sensor_msgs::msg::Image img_send;

			RCLCPP_INFO(vos->get_logger(), "Image segmented.");
			segmentation.toImageMsg(img_send);
			vos->segmentation_pub_->publish(img_send);
		}
		executor.spin_once();
	}

	rclcpp::shutdown();
}

// End of Include declaration (body)

namespace VOSCompdef {

// static attributes (if any)

/**
 * 
 * @param options 
 */

void VOS::fNewFunction(
		const sensor_msgs::msg::Image::SharedPtr /*in*/image) {
	img_msg = *image;
	RCLCPP_INFO(this->get_logger(),"Image received!");
}


VOS::VOS(rclcpp::NodeOptions /*in*/options) :
		rclcpp_lifecycle::LifecycleNode("VOS", options) {
	segmentation_pub_ = create_publisher<sensor_msgs::msg::Image>(
			"segmentation", 1);
	// directly activate a publisher
	segmentation_pub_->on_activate();

	image_sub_ = create_subscription<sensor_msgs::msg::Image>("image",
			rclcpp::QoS(rclcpp::KeepLast(100)).best_effort(),
			std::bind(&VOSCompdef::VOS::fNewFunction, (VOS*) this,
					std::placeholders::_1));

}

} // of namespace VOSCompdef

/************************************************************
 End of VOS class body
 ************************************************************/


void segmentImage( Mat& img, torch::jit::script::Module module )
{
	cv::cvtColor(img, img, CV_BGR2RGB);
	img.convertTo(img, CV_32FC3, 1.0f / 255.0f);
	auto input_tensor = torch::from_blob(img.data, {1, img.rows, img.cols, 3});
	input_tensor = input_tensor.permute({0, 3, 1, 2});


	std::vector<torch::jit::IValue> inputs;
	inputs.push_back(input_tensor);

	torch::Tensor n_FG;
	torch::Tensor annotated_tensor;

	if (!runningFGmean.defined())
	{
		// Load annotated frame
		cv::Mat img1 = cv::imread(annotated_path, CV_8UC1);
		//cv::waitKey();
		//cv::cvtColor(annotated_frame, annotated_frame, CV_BGR2RGB);
		cv::Mat img_float;
		img1.convertTo(img_float, CV_32F, 1.0);
		annotated_tensor = torch::from_blob(img_float.data, {1, img_float.rows, img_float.cols, 1});
		annotated_tensor = annotated_tensor.permute({0, 3, 1, 2});

		n_FG = annotated_tensor.sum({2,3});
	}


	module.eval();
	{
		torch::NoGradGuard no_grad;
		torch::Tensor out_tensor = module.forward(inputs).toTensor();

		float eps = 1e-5;
		int N = out_tensor.sizes()[2] * out_tensor.sizes()[3];
		int margin = 0;


		if (!runningFGmean.defined())
		{
			// Set Running Means for initial step
			torch::Tensor foreground = out_tensor * annotated_tensor;

			torch::Tensor background = out_tensor * (1-annotated_tensor);
			runningFGmean = foreground.sum({2,3}, true) / (n_FG + eps);
			runningBGmean = background.sum({2,3}, true) / (N - n_FG + eps);

			// Set margin to 0 for initial frame
			margin = 0;
		}


		torch::Tensor distFG = (out_tensor - runningFGmean).square().mean({1}, true);
		torch::Tensor distBG = (out_tensor - runningBGmean).square().mean({1}, true);

		torch::Tensor predMask = torch::ones_like(distFG).where(distFG + margin < distBG, torch::zeros_like(distFG));


		n_FG = predMask.sum({2,3});

		torch::Tensor foreground = out_tensor * predMask;
		torch::Tensor background = out_tensor * (1-predMask);

		torch::Tensor mean_FG = foreground.sum({2,3}, true) / (n_FG + eps);
		torch::Tensor mean_BG = background.sum({2,3}, true) / (N - n_FG + eps);

		runningFGmean = mean_FG.mean({0}, true);
		runningBGmean = mean_BG.mean({0}, true);


		torch::Tensor res_im = predMask[0].detach();
		res_im = res_im.permute({1, 2, 0});
		res_im = res_im.mul(255).clamp(0, 255).to(torch::kU8);
		res_im = res_im.to(torch::kCPU);

		cv::Mat out(img.rows,
					img.cols,
					CV_8UC1,
					res_im.data_ptr());

	    // Show Processed Image with detected faces
		cv::Mat grey_3_channel;
		out.convertTo(grey_3_channel, CV_32FC1, 1.0f / 255.0f);
		cv::cvtColor(grey_3_channel, grey_3_channel, CV_GRAY2BGR);

		cv::Mat images;
		cv::hconcat(img, grey_3_channel, images);

		//std::string name = "seg_output" + std::to_string(count) + ".png";
		//cv::imwrite(name, images);
	    imshow( "Output Images", images );
	    //cv::waitKey();
	    count++;

	    seg_mask = out;
	}
}




